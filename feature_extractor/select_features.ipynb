{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd09e3331f33eb389195482b1aa660dd29a9ded8809cf5ab163519b8776dee9d80b",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from os import listdir, mkdir\n",
    "from os.path import isdir, join\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pickle import dump, load\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import re\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = \"../../Data/feature_vectors\"\n",
    "SHA_CSV_PATH = \"../../Data/sha256_family.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Shadow/Desktop/PFE/Projet_Mathias/projet-de-recherche/Data/generated/features-u-pr-sr-ac-i-per_count.p', 'rb') as file:\n",
    "        features = load(file) # Valeurs possibles des features \n",
    "\n",
    "feature_set = {\n",
    "    'feature': set(),  # Hardware Components 72\n",
    "    'permission': set(),  # Requested Permission 3812\n",
    "    'activity': set(),  # App Components p1 185729\n",
    "    'service_receiver': set(),  # App Component p2 33222\n",
    "    'provider': set(),  # App Component p3# : 4513\n",
    "    'intent': set(),  # Filtered Intent 6379\n",
    "    'call': set(),  # Restricted Api Calls 733\n",
    "    'real_permission': set(),  # Used Permission 70\n",
    "    'api_call': set(),  # = Suspicious Api Calls 315\n",
    "    'url': set(),  # Network Address 310488\n",
    "}\n",
    "\n",
    "for l in features:\n",
    "    l_split = l.split('::')\n",
    "    if len(l_split) > 1:\n",
    "        feature_set[l_split[0]].add(l_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_full = [f for f in listdir(FEATURES_PATH)]\n",
    "paths = random.sample(paths_full, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malwares = pd.read_csv(SHA_CSV_PATH, sep=\",\")\n",
    "malwares.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(paths, malwares, subset_name, features_names, func, features_complete=True):\n",
    "\n",
    "    name_malwares = malwares['sha256'].tolist()\n",
    "\n",
    "    matrix = np.zeros((len(paths),len(features_names)), dtype=np.uint8)\n",
    "\n",
    "    for i, path in enumerate(paths):\n",
    "        \n",
    "        is_malware = False\n",
    "        if path in name_malwares:\n",
    "            is_malware = True\n",
    "        matrix[i,0] = int(is_malware)\n",
    "\n",
    "        full_path = join(FEATURES_PATH, path)\n",
    "        with open(full_path, 'r') as file:\n",
    "            lines = file.read().splitlines()\n",
    "            lines = [sl.split('::') for sl in lines]\n",
    "            if len(lines) > 1:\n",
    "                for line in lines:\n",
    "                    name = line[0]\n",
    "                    value = line[1]\n",
    "                    if name == subset_name:\n",
    "                        if features_complete:\n",
    "                            index_sub = np.where(features_names == value)[0][0]\n",
    "                            matrix[i,index_sub] += 1            \n",
    "\n",
    "                        list_index = func(value, features_names)\n",
    "                        for elem in list_index:\n",
    "                            matrix[i,elem] += 1  \n",
    "\n",
    "\n",
    "    data = pd.DataFrame(matrix, columns=features_names, index=paths)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(X, y, percent=0.8):\n",
    "\n",
    "    # For Person, Chi-2 and RFE, need to specifie the number of features we keep\n",
    "    num_feats = int(X.shape[1]*percent)\n",
    "\n",
    "    ### Pearson correlation\n",
    "\n",
    "    def cor_selector(X, y,num_feats):\n",
    "        cor_list = []\n",
    "        feature_name = X.columns.tolist()\n",
    "        # calculate the correlation with y for each feature\n",
    "        for elem in X.columns.tolist():\n",
    "            cor = np.corrcoef(X[elem], y)[0, 1]\n",
    "            cor_list.append(cor)\n",
    "        # replace NaN with 0\n",
    "        cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "\n",
    "        cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "        # feature selection? 0 for not select, 1 for select\n",
    "\n",
    "        cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "        return cor_support, cor_feature\n",
    "\n",
    "    cor_support, cor_feature = cor_selector(X, y, num_feats)\n",
    "    cor_ranking = cor_feature[::-1]\n",
    "\n",
    "    ### Chi-2\n",
    "\n",
    "    X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "    chi_selector = SelectKBest(chi2, k=num_feats)\n",
    "    chi_selector.fit(X_norm, y)\n",
    "    chi_support = chi_selector.get_support()\n",
    "    chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "\n",
    "    chi_list = [0 if np.isnan(i) else i for i in chi_selector.scores_]\n",
    "    chi_feature = X.iloc[:,np.argsort(np.abs(chi_list))].columns.tolist()\n",
    "    chi_ranking = chi_feature[::-1]\n",
    "    \n",
    "    ### RFE\n",
    "\n",
    "    rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_feats, step=X.shape[1]*0.1, verbose=5)\n",
    "    rfe_selector.fit(X_norm, y)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "    print(str(len(rfe_feature)), 'selected features')\n",
    "\n",
    "    RFE_feature = X.iloc[:,rfe_support].iloc[:,np.argsort(np.abs(rfe_selector.estimator_.coef_[0]))].columns.tolist()\n",
    "    RFE_ranking = RFE_feature[::-1]\n",
    "\n",
    "    ### Logistic Regression\n",
    "\n",
    "    embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=num_feats)\n",
    "    embeded_lr_selector.fit(X_norm, y)\n",
    "\n",
    "    embeded_lr_support = embeded_lr_selector.get_support()\n",
    "    embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "\n",
    "    lr_feature = X.iloc[:,np.argsort(np.abs(embeded_lr_selector.estimator_.coef_[0]))].columns.tolist()\n",
    "    lr_ranking = lr_feature[::-1]\n",
    "\n",
    "    ### Random Forest\n",
    "\n",
    "    embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=num_feats)\n",
    "    embeded_rf_selector.fit(X, y)\n",
    "\n",
    "    embeded_rf_support = embeded_rf_selector.get_support()\n",
    "    embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "    rf_feature = X.iloc[:,np.argsort(embeded_rf_selector.estimator_.feature_importances_)].columns.tolist()\n",
    "    rf_ranking = rf_feature[::-1]\n",
    "\n",
    "    ### Light GBM\n",
    "    \n",
    "    #X_rename = X.rename(columns = lambda x: x.replace('.','0'))\n",
    "    #X_rename = X_rename.rename(columns = lambda x: x.replace(':','1'))\n",
    "    #X_rename = X_rename.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '2', x))\n",
    "    #X_rename = X_rename.rename(columns = lambda x: x[:max(-30, -len(x))])\n",
    "    X_rename = X.copy()\n",
    "    X_rename.columns = [str(int(x)) for x in np.arange(len(X.columns.tolist()))]\n",
    "\n",
    "    lgbc=LGBMClassifier(n_estimators=1000)\n",
    "\n",
    "    embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
    "    embeded_lgb_selector.fit(X_rename, y)\n",
    "\n",
    "    embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "    embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
    "    lgb_feature = X.iloc[:,np.argsort(embeded_lgb_selector.estimator_.feature_importances_)].columns.tolist()\n",
    "    lgb_ranking = lgb_feature[::-1]\n",
    "\n",
    "    # put all selection together\n",
    "    feature_selection_df = pd.DataFrame({'Feature':X.columns, 'Pearson':cor_support, 'Chi-2':chi_support,'Logistics':embeded_lr_support,\n",
    "                                        'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support})\n",
    "\n",
    "    # count the selected times for each feature\n",
    "    feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "\n",
    "    feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "    feature_selection_df.set_index('Feature', inplace=True)\n",
    "    \n",
    "    cor_ranking_df = [(cor_ranking.index(elem)+1) if elem in cor_ranking else (num_feats+1) for elem in X.columns]\n",
    "    chi_ranking_df = [(chi_ranking.index(elem)+1) if elem in chi_ranking else (num_feats+1) for elem in X.columns]\n",
    "    RFE_ranking_df = [(RFE_ranking.index(elem)+1) if elem in RFE_ranking else (num_feats+1) for elem in X.columns]\n",
    "    lr_ranking_df = [(lr_ranking.index(elem)+1) if elem in lr_ranking else (num_feats+1) for elem in X.columns]\n",
    "    rf_ranking_df = [(rf_ranking.index(elem)+1) if elem in rf_ranking else (num_feats+1) for elem in X.columns]\n",
    "    lgb_ranking_df = [(lgb_ranking.index(elem)+1) if elem in lgb_ranking else (num_feats+1) for elem in X.columns]\n",
    "\n",
    "\n",
    "    feature_ranking_df = pd.DataFrame({'Feature':X.columns, 'Pearson':cor_ranking_df, 'Chi-2':chi_ranking_df, 'Logistics':lr_ranking_df, 'Random Forest':rf_ranking_df, 'LightGBM':lgb_ranking_df})\n",
    "\n",
    "    feature_ranking_df.set_index('Feature', inplace=True)\n",
    "    feature_ranking_df['Ranking'] = feature_ranking_df.prod(axis=1).pow(1/5) # 6 because 6 models\n",
    "    feature_ranking_df = feature_ranking_df.sort_values('Ranking')\n",
    "\n",
    "    return feature_selection_df, feature_ranking_df"
   ]
  },
  {
   "source": [
    "## Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"feature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_feature(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        if x_split[1] == 'software':\n",
    "            index_sub = np.where(features_names == 'software')[0][0]\n",
    "            list_index.append(index_sub)\n",
    "\n",
    "    return list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_spe = ['software']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_name = np.array(['malware'] + list(feature_set[subset_name]) + list_spe)\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_feature)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature, feature_ranking_df = selection(X, y)\n",
    "result_feature = pd.merge(feature_ranking_df, select_feature[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_feature.head(30)"
   ]
  },
  {
   "source": [
    "## Permission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"permission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_permission(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[-1]\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['permission']:\n",
    "    x_split = elem.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[-1])\n",
    "\n",
    "list_spe.add('autre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = np.array(['malware'] + list(set(list(feature_set[subset_name]) + list(list_spe))))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_permission)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_permissions, permissions_ranking_df = selection(X, y)\n",
    "result_permissions = pd.merge(permissions_ranking_df, select_permissions[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_permissions.head(30)"
   ]
  },
  {
   "source": [
    "## Service receiver"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"service_receiver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_service(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[0]\n",
    "        if sub == '':\n",
    "            sub = '.'\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['service_receiver']:\n",
    "    x_split = elem.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[0])\n",
    "\n",
    "list_spe.add('autre')\n",
    "list_spe.add('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = np.array(['malware'] + list(list_spe))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_service, False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_service, service_ranking_df = selection(X, y)\n",
    "result_service = pd.merge(service_ranking_df, select_service[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_service.head(30)"
   ]
  },
  {
   "source": [
    "## Provider"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_provider(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[0]\n",
    "        if sub == '':\n",
    "            sub =  '.'\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"provider\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['provider']:\n",
    "    x_split = elem.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[0])\n",
    "\n",
    "list_spe.add('autre')\n",
    "list_spe.add('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = np.array(['malware'] + list(set(list(feature_set[subset_name]) + list(list_spe))))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_provider)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_provider, provider_ranking_df = selection(X, y)\n",
    "result_provider = pd.merge(provider_ranking_df, select_provider[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_provider.head(30)"
   ]
  },
  {
   "source": [
    "## Intent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_intent(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[-1]\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index\n",
    "\n",
    "\n",
    "subset_name = \"intent\"\n",
    "\n",
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['intent']:\n",
    "    x_split = elem.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[-1])\n",
    "\n",
    "list_spe.add('autre')\n",
    "\n",
    "columns_name = np.array(['malware'] + list(set(list(feature_set[subset_name]) + list(list_spe))))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_intent)\n",
    "\n",
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "select_intent, intent_ranking_df = selection(X, y)\n",
    "result_intent = pd.merge(intent_ranking_df, select_intent[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_intent.head(30)"
   ]
  },
  {
   "source": [
    "## Call"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_call(value, features_names):\n",
    "    list_index = []\n",
    "    if value[:6] == 'Cipher':\n",
    "        sub = 'Cipher'\n",
    "    elif value[:3] == 'get':\n",
    "        sub = 'get'\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index\n",
    "\n",
    "\n",
    "subset_name = \"call\"\n",
    "\n",
    "list_spe = set()\n",
    "\n",
    "list_spe.add('Cipher')\n",
    "list_spe.add('get')\n",
    "list_spe.add('autre')\n",
    "\n",
    "columns_name = np.array(['malware'] + list(set(list(feature_set[subset_name]) + list(list_spe))))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_call)\n",
    "\n",
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "select_call, call_ranking_df = selection(X, y)\n",
    "result_call = pd.merge(call_ranking_df, select_call[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_call.head(30)"
   ]
  },
  {
   "source": [
    "## Real permission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_real(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[0]\n",
    "        if sub == '':\n",
    "            sub = '.'\n",
    "        sub2 = x_split[-1]\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "    index_sub2 = np.where(features_names == sub2)[0][0]\n",
    "    list_index.append(index_sub2)\n",
    "\n",
    "    return list_index\n",
    "\n",
    "\n",
    "subset_name = \"real_permission\"\n",
    "\n",
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['real_permission']:\n",
    "    x_split = elem.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[0])\n",
    "        list_spe.add(x_split[-1])\n",
    "\n",
    "list_spe.add('.')\n",
    "list_spe.add('autre')\n",
    "\n",
    "columns_name = np.array(['malware'] + list(set(list(feature_set[subset_name]) + list(list_spe))))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_real)\n",
    "\n",
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "select_real, real_ranking_df = selection(X, y)\n",
    "result_real = pd.merge(real_ranking_df, select_real[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_real.head(30)"
   ]
  },
  {
   "source": [
    "## Api call"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_api(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split(';->')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[-1]\n",
    "    else:\n",
    "        sub = 'autre'\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index\n",
    "\n",
    "\n",
    "subset_name = \"api_call\"\n",
    "\n",
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['api_call']:\n",
    "    x_split = elem.split(';->')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[-1])\n",
    "\n",
    "list_spe.add('autre')\n",
    "\n",
    "columns_name = np.array(['malware'] + list(set(list(feature_set[subset_name]) + list(list_spe))))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_permission)\n",
    "\n",
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "select_api, api_ranking_df = selection(X, y)\n",
    "result_api = pd.merge(api_ranking_df, select_api[['Total']].rename(columns={'Total':'Selection'}), left_index=True, right_index=True)\n",
    "result_api.head(30)"
   ]
  },
  {
   "source": [
    "## Activity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_activity(value, features_names):\n",
    "    list_index = []\n",
    "    x_split = value.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        sub = x_split[-1]\n",
    "    else:\n",
    "        sub = value\n",
    "\n",
    "    index_sub = np.where(features_names == sub)[0][0]\n",
    "    list_index.append(index_sub)\n",
    "\n",
    "    return list_index\n",
    "\n",
    "\n",
    "subset_name = \"activity\"\n",
    "\n",
    "list_spe = set()\n",
    "\n",
    "for elem in feature_set['activity']:\n",
    "    x_split = elem.split('.')\n",
    "    if len(x_split) > 1:\n",
    "        list_spe.add(x_split[-1])\n",
    "    else:\n",
    "        list_spe.add(elem)\n",
    "\n",
    "list_spe.add('autre')\n",
    "print(len(list_spe))\n",
    "columns_name = np.array(['malware'] + list(list_spe))\n",
    "data = generate_dataframe(paths, malwares, subset_name, columns_name, infos_activity, False)\n",
    "\n",
    "# Create X from the features\n",
    "X = data.drop(columns='malware')\n",
    "\n",
    "# Create y from output\n",
    "y = data['malware']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# select_provider = selection(X, y)\n",
    "\n",
    "# select_provider.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_dataframe(paths_full, malwares, subset_name, columns_name, infos_activity, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum()"
   ]
  }
 ]
}